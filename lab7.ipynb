{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vkEKksTX2hix",
        "outputId": "d17f125b-4005-4618-a0f7-d1bad3549a9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#configuraci칩n en google colab de spark y pyspark\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "f5dtzEjX2hiz"
      },
      "outputs": [],
      "source": [
        "#instalar java y spark\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark\n",
        "\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\"\n",
        "\n",
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_6roqIRw2hiz"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "#forma 1 de crear la sesi칩n y el contexto Spark:\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext\n",
        "\n",
        "#forma 2 de crear la sesi칩n y el contexto Spark:\n",
        "#sc = SparkContext.getOrCreate()\n",
        "#spark=SparkSession.builder.appName('nlp').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [],
        "id": "gLK7wblp2hiz"
      },
      "outputs": [],
      "source": [
        "#myrdd = sc.wholeTextFiles('../datasets/papers_sample_pdf/*.txt')\n",
        "#df = myrdd.toDF(schema=['filename','content'])\n",
        "#df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "4HM6eSa12hiz"
      },
      "outputs": [],
      "source": [
        "df=spark.createDataFrame([(1,'I really liked this movie'),\n",
        "                         (2,'I would recommend this movie to my friends'),\n",
        "                         (3,'movie was alright but acting was horrible'),\n",
        "                         (4,'I am never watching that movie ever again')],\n",
        "                        ['user_id','content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "89D6mclZ2hi0",
        "outputId": "c562d011-7e35-4d41-93f2-b409a44cb2c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- content: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M_xkhldZ2hi0",
        "outputId": "b9ae2a70-b99c-43f4-d744-23a39c39f505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- user_id: long (nullable = true)\n",
            " |-- content: string (nullable = true)\n",
            " |-- tokens: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            "\n",
            "+-------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|\n",
            "+-------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|\n",
            "|      2|I would recommend...|[i, would, recomm...|\n",
            "|      3|movie was alright...|[movie, was, alri...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|\n",
            "+-------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Tokenization\n",
        "from pyspark.ml.feature import Tokenizer\n",
        "tokenization=Tokenizer(inputCol='content',outputCol='tokens')\n",
        "tokenized_df=tokenization.transform(df)\n",
        "tokenized_df.printSchema()\n",
        "tokenized_df.show(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VHfOcOzA2hi0",
        "outputId": "41739e57-7d65-4477-d205-81c8b28156cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------+----------------------------------+\n",
            "|tokens                                             |refined_tokens                    |\n",
            "+---------------------------------------------------+----------------------------------+\n",
            "|[i, really, liked, this, movie]                    |[really, liked, movie]            |\n",
            "|[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |\n",
            "|[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|\n",
            "|[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |\n",
            "+---------------------------------------------------+----------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# stopwords removal \n",
        "from pyspark.ml.feature import StopWordsRemover\n",
        "stopword_removal=StopWordsRemover(inputCol='tokens',outputCol='refined_tokens')\n",
        "refined_df=stopword_removal.transform(tokenized_df)\n",
        "refined_df.select(['tokens','refined_tokens']).show(10,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "CfHU7f8x2hi0",
        "outputId": "ff50269b-260e-4283-9cc7-0a40e49205f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user_id', 'content', 'tokens', 'refined_tokens']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "refined_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jm9acwTa2hi0"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "from pyspark.sql.functions import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "T6sG4sQF2hi0"
      },
      "outputs": [],
      "source": [
        "len_udf = udf(lambda s: len(s), IntegerType())\n",
        "\n",
        "refined_count_df = refined_df.withColumn(\"token_count\", len_udf(col('refined_tokens')))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pMOujvxd2hi0",
        "outputId": "e3a875b4-10e5-4d3c-89a2-6b57cc3f5651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "|user_id|             content|              tokens|      refined_tokens|token_count|\n",
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|          3|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|          4|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|          4|\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|          3|\n",
            "+-------+--------------------+--------------------+--------------------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "refined_count_df.orderBy(rand()).show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oiXfxGn22hi1",
        "outputId": "534387e4-c207-47ce-af5e-e55fc83d0880",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------+---------------------------------+\n",
            "|refined_tokens                    |features                         |\n",
            "+----------------------------------+---------------------------------+\n",
            "|[really, liked, movie]            |(11,[0,2,3],[1.0,1.0,1.0])       |\n",
            "|[recommend, movie, friends]       |(11,[0,6,7],[1.0,1.0,1.0])       |\n",
            "|[movie, alright, acting, horrible]|(11,[0,1,5,10],[1.0,1.0,1.0,1.0])|\n",
            "|[never, watching, movie, ever]    |(11,[0,4,8,9],[1.0,1.0,1.0,1.0]) |\n",
            "+----------------------------------+---------------------------------+\n",
            "\n",
            "['movie', 'horrible', 'liked', 'really', 'watching', 'alright', 'friends', 'recommend', 'ever', 'never', 'acting']\n"
          ]
        }
      ],
      "source": [
        "# Count Vectorizer\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "count_vec=CountVectorizer(inputCol='refined_tokens',outputCol='features')\n",
        "cv_df=count_vec.fit(refined_df).transform(refined_df)\n",
        "cv_df.select(['refined_tokens','features']).show(4,False)\n",
        "bow = count_vec.fit(refined_df).vocabulary\n",
        "print(bow)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dO08vTjJ2hi1",
        "outputId": "c0e7ae95-b565-4330-92ac-e3e172d32126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|user_id|             content|              tokens|      refined_tokens|         tf_features|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "|      1|I really liked th...|[i, really, liked...|[really, liked, m...|(11,[9,10],[2.0,1...|\n",
            "|      2|I would recommend...|[i, would, recomm...|[recommend, movie...|(11,[1,6,9],[1.0,...|\n",
            "|      3|movie was alright...|[movie, was, alri...|[movie, alright, ...|(11,[1,6,9,10],[1...|\n",
            "|      4|I am never watchi...|[i, am, never, wa...|[never, watching,...|(11,[0,7,8,9],[1....|\n",
            "+-------+--------------------+--------------------+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# TF with HashingTF\n",
        "from pyspark.ml.feature import HashingTF\n",
        "# podria utilizar numFeatures como el tama침o del Bag of Words:\n",
        "l = len(bow)\n",
        "hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=l)\n",
        "#hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features',numFeatures=11)\n",
        "# compare la salida e interprete con y sin numFeatures:\n",
        "#hashing_vec=HashingTF(inputCol='refined_tokens',outputCol='tf_features')\n",
        "\n",
        "hashing_df=hashing_vec.transform(refined_df)\n",
        "hashing_df.show(4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8mUfMfCZ2hi1",
        "outputId": "a4dcbb65-3bfe-485f-ab59-64c0cf60b92e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "|user_id|content                                   |tokens                                             |refined_tokens                    |tf_features                      |tf_idf_features                                                               |\n",
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "|1      |I really liked this movie                 |[i, really, liked, this, movie]                    |[really, liked, movie]            |(11,[9,10],[2.0,1.0])            |(11,[9,10],[0.0,0.5108256237659907])                                          |\n",
            "|2      |I would recommend this movie to my friends|[i, would, recommend, this, movie, to, my, friends]|[recommend, movie, friends]       |(11,[1,6,9],[1.0,1.0,1.0])       |(11,[1,6,9],[0.5108256237659907,0.5108256237659907,0.0])                      |\n",
            "|3      |movie was alright but acting was horrible |[movie, was, alright, but, acting, was, horrible]  |[movie, alright, acting, horrible]|(11,[1,6,9,10],[1.0,1.0,1.0,1.0])|(11,[1,6,9,10],[0.5108256237659907,0.5108256237659907,0.0,0.5108256237659907])|\n",
            "|4      |I am never watching that movie ever again |[i, am, never, watching, that, movie, ever, again] |[never, watching, movie, ever]    |(11,[0,7,8,9],[1.0,1.0,1.0,1.0]) |(11,[0,7,8,9],[0.9162907318741551,0.9162907318741551,0.9162907318741551,0.0]) |\n",
            "+-------+------------------------------------------+---------------------------------------------------+----------------------------------+---------------------------------+------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import IDF\n",
        "tf_idf_vec=IDF(inputCol='tf_features',outputCol='tf_idf_features')\n",
        "tf_idf_df=tf_idf_vec.fit(hashing_df).transform(hashing_df)\n",
        "tf_idf_df.show(4,False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
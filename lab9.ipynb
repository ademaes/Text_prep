{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7kCYySwQ4ZDd",
        "outputId": "53af4e6e-51c1-4204-e990-d5a230baa331",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "#configuración en google colab de spark y pyspark\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0M3sKPMA4ZDe"
      },
      "outputs": [],
      "source": [
        "#instalar java y spark\n",
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://downloads.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz\n",
        "!tar xf spark-3.3.2-bin-hadoop3.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rzXFKchq4ZDf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.3.2-bin-hadoop3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "83n7Sb8m4ZDf"
      },
      "outputs": [],
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
        "sc = spark.sparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvwPFXbK4ZDg"
      },
      "outputs": [],
      "source": [
        "# configuración local de pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CC4e0eCg4ZDg"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import monotonically_increasing_id, col, expr, when, concat, lit, isnan\n",
        "from pyspark.ml.linalg import Vectors\n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "from pyspark.ml.classification import RandomForestClassifier, LogisticRegression\n",
        "from pyspark.ml.feature import VectorIndexer, VectorAssembler, StringIndexer, OneHotEncoder\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, RegressionEvaluator, BinaryClassificationEvaluator\n",
        "from pyspark.ml import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3m49jwVu4ZDg"
      },
      "outputs": [],
      "source": [
        "#from pyspark import SparkContext\n",
        "#sc = SparkContext(\"local\", \"airlines\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EATl-g7Q4ZDg"
      },
      "outputs": [],
      "source": [
        "#from pyspark.sql import SparkSession\n",
        "#spark = SparkSession.builder.appName('airlines').getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s-QKhplm4ZDg",
        "outputId": "d7bc36f5-eec0-48eb-ba86-f8a09a8c85aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+\n",
            "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+\n",
            "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|\n",
            "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|\n",
            "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|\n",
            "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|\n",
            "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|\n",
            "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|\n",
            "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|\n",
            "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|\n",
            "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|\n",
            "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df=spark.read.csv(\"gdrive/MyDrive/st1800-231/datasets/airlines.csv\", inferSchema=True, header=True)\n",
        "#df=spark.read.csv(\"../datasets/airlines.csv\", inferSchema=True, header=True)\n",
        "\n",
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-ptHAPd24ZDh",
        "outputId": "7bfa4f3e-969f-4365-ac9a-d49f97021c2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------+---------+---------+------+--------+-----+-----------+--------------------+\n",
            "|   id|        airline|     date| location|rating|   cabin|value|recommended|              review|\n",
            "+-----+---------------+---------+---------+------+--------+-----+-----------+--------------------+\n",
            "|10001|Delta Air Lines|21-Jun-14| Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|\n",
            "|10002|Delta Air Lines|19-Jun-14|      USA|     0| Economy|    2|         NO|Flight 2463 leavi...|\n",
            "|10003|Delta Air Lines|18-Jun-14|      USA|     0| Economy|    1|         NO|Delta Website fro...|\n",
            "|10004|Delta Air Lines|17-Jun-14|      USA|     9|Business|    4|        YES|\"I just returned ...|\n",
            "|10005|Delta Air Lines|17-Jun-14|  Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|\n",
            "|10006|Delta Air Lines|17-Jun-14|      USA|     9|Business|    5|        YES|Narita - Bangkok ...|\n",
            "|10007|Delta Air Lines|14-Jun-14|       UK|     0| Economy|    1|         NO|Flight from NY La...|\n",
            "|10008|Delta Air Lines|14-Jun-14|      USA|     0| Economy|    1|         NO|Originally I had ...|\n",
            "|10009|Delta Air Lines|13-Jun-14|      USA|     4|Business|    2|         NO|We flew paid busi...|\n",
            "|10010|Delta Air Lines|13-Jun-14|       UK|     9| Economy|    3|        YES|\"I flew from Heat...|\n",
            "|10011|Delta Air Lines|11-Jun-14|      USA|    10| Economy|    4|        YES|I was a bit stubb...|\n",
            "|10012|Delta Air Lines|10-Jun-14|Australia|    10| Economy|    5|        YES|JFK-LHR. Had a gr...|\n",
            "|10013|Delta Air Lines| 9-Jun-14|      USA|     0| Economy|    1|         NO|My wife and I fly...|\n",
            "|10014|Delta Air Lines| 9-Jun-14|      USA|    10| Premium|    5|        YES|DL 1134 PBI-ATL. ...|\n",
            "|10015|Delta Air Lines| 6-Jun-14|      USA|     0| Economy|    2|         NO|Our flight from F...|\n",
            "|10016|Delta Air Lines| 5-Jun-14|      USA|     0| Economy|    1|         NO|On May 22 after a...|\n",
            "|10017|Delta Air Lines| 3-Jun-14|   Canada|     9| Economy|    4|        YES|Considering how D...|\n",
            "|10018|Delta Air Lines| 2-Jun-14|      USA|     9| Economy|    5|        YES|Travelled MSP-LHR...|\n",
            "|10019|Delta Air Lines|29-May-14|      USA|     7|Business|    2|        YES|JFK-LAX on a 757-...|\n",
            "|10020|Delta Air Lines|28-May-14|       UK|     9| Economy|    3|        YES|Third long haul f...|\n",
            "+-----+---------------+---------+---------+------+--------+-----+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.createOrReplaceTempView(\"train_df\")\n",
        "sqlDF = spark.sql(\"SELECT * FROM train_df\")\n",
        "sqlDF.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "R9wE1C7q4ZDh"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import codecs\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7KStE-JN4ZDh",
        "outputId": "6d754b23-0696-4137-88d1-07337e94ef02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nYJDyRX14ZDh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# stopwords en nltk\n",
        "from nltk.corpus import stopwords\n",
        " \n",
        "stop_words_nltk = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lnRLWium4ZDh"
      },
      "outputs": [],
      "source": [
        "from pyspark.ml.feature import HashingTF, IDF, Tokenizer, CountVectorizer\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.ml.linalg import Vectors, SparseVector\n",
        "from pyspark.ml.clustering import LDA, BisectingKMeans\n",
        "from pyspark.sql.functions import monotonically_increasing_id\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7EOV07024ZDh",
        "outputId": "97a23c44-6443-4571-f97b-538ad49ca1bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- id: string (nullable = true)\n",
            " |-- airline: string (nullable = true)\n",
            " |-- date: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- rating: string (nullable = true)\n",
            " |-- cabin: string (nullable = true)\n",
            " |-- value: string (nullable = true)\n",
            " |-- recommended: string (nullable = true)\n",
            " |-- review: string (nullable = true)\n",
            "\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
            "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|uid|year_month|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
            "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|  0|    21-Jun|\n",
            "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|  1|    19-Jun|\n",
            "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|  2|    18-Jun|\n",
            "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|  3|    17-Jun|\n",
            "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|  4|    17-Jun|\n",
            "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|  5|    17-Jun|\n",
            "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|  6|    14-Jun|\n",
            "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|  7|    14-Jun|\n",
            "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|  8|    13-Jun|\n",
            "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|  9|    13-Jun|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+---+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "('id', 'string')\n",
            "('airline', 'string')\n",
            "('date', 'string')\n",
            "('location', 'string')\n",
            "('rating', 'string')\n",
            "('cabin', 'string')\n",
            "('value', 'string')\n",
            "('recommended', 'string')\n",
            "('review', 'string')\n",
            "('uid', 'bigint')\n",
            "('year_month', 'string')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('rating', 'int')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "rawdata = spark.read.load(\"gdrive/MyDrive/st1800-231/datasets/airlines.csv\", format=\"csv\", header=True)\n",
        "rawdata.printSchema()\n",
        "rawdata[0]\n",
        "rawdata = rawdata.fillna({'review': ''})                               # Replace nulls with blank string\n",
        "\n",
        "# Add Unique ID\n",
        "rawdata = rawdata.withColumn(\"uid\", monotonically_increasing_id())     # Create Unique ID\n",
        "\n",
        "# Generate YYYY-MM variable\n",
        "rawdata = rawdata.withColumn(\"year_month\", rawdata.date.substr(1,6))\n",
        "\n",
        "# Show rawdata (as DataFrame)\n",
        "rawdata.show(10)\n",
        "\n",
        "# Print data types\n",
        "for type in rawdata.dtypes:\n",
        "    print(type)\n",
        "\n",
        "target = rawdata.select(rawdata['rating'].cast(IntegerType()))\n",
        "target.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KLmIOPeq4ZDi",
        "outputId": "9c84a2cb-8b9a-4f03-8c5b-8450fd919e0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+\n",
            "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|              words|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+\n",
            "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|[delta, air, lines]|\n",
            "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|[delta, air, lines]|\n",
            "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|[delta, air, lines]|\n",
            "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|[delta, air, lines]|\n",
            "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|[delta, air, lines]|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "################################################################################################\n",
        "#\n",
        "#   Text Pre-processing (consider using one or all of the following):\n",
        "#       - Remove common words (with stoplist)\n",
        "#       - Handle punctuation\n",
        "#       - lowcase/upcase\n",
        "#       - Stemming\n",
        "#       - Part-of-Speech Tagging (nouns, verbs, adj, etc.)\n",
        "#\n",
        "################################################################################################\n",
        "from pyspark.sql.functions import udf,struct\n",
        "#from pyspark.sql.types import StructType\n",
        "def textprep(record):\n",
        "    text  = record[1]\n",
        "    uid   = record[0]\n",
        "    tokens = text.split()\n",
        "       \n",
        "    # Custom List of Stopwords - Add your own here\n",
        "    tokens = [re.sub('[^a-zA-Z0-9]','',word) for word in tokens]                                       # Remove special characters\n",
        "    tokens = [word.lower() for word in tokens if len(word)>2 and word.lower() not in stop_words_nltk]     # Remove stopwords and words under X length\n",
        "    return tokens\n",
        "\n",
        "udf_textprep = udf(textprep , ArrayType(StringType()))\n",
        "df = df.withColumn(\"words\", udf_textprep(struct([df[x] for x in df.columns])))\n",
        "\n",
        "#tokenizer = Tokenizer(inputCol=\"description\", outputCol=\"words\")\n",
        "#wordsData = tokenizer.transform(text)\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hikzLPIt4ZDi",
        "outputId": "d2dccfc4-a94c-494c-ff23-7d9f516bd0a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+--------------------+--------------------+\n",
            "|   id|        airline|     date|location|rating|   cabin|value|recommended|              review|              words|         rawFeatures|            features|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+--------------------+--------------------+\n",
            "|10001|Delta Air Lines|21-Jun-14|Thailand|     7| Economy|    4|        YES|Flew Mar 30 NRT t...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10002|Delta Air Lines|19-Jun-14|     USA|     0| Economy|    2|         NO|Flight 2463 leavi...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10003|Delta Air Lines|18-Jun-14|     USA|     0| Economy|    1|         NO|Delta Website fro...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10004|Delta Air Lines|17-Jun-14|     USA|     9|Business|    4|        YES|\"I just returned ...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10005|Delta Air Lines|17-Jun-14| Ecuador|     7| Economy|    3|        YES|\"Round-trip fligh...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10006|Delta Air Lines|17-Jun-14|     USA|     9|Business|    5|        YES|Narita - Bangkok ...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10007|Delta Air Lines|14-Jun-14|      UK|     0| Economy|    1|         NO|Flight from NY La...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10008|Delta Air Lines|14-Jun-14|     USA|     0| Economy|    1|         NO|Originally I had ...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10009|Delta Air Lines|13-Jun-14|     USA|     4|Business|    2|         NO|We flew paid busi...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "|10010|Delta Air Lines|13-Jun-14|      UK|     9| Economy|    3|        YES|\"I flew from Heat...|[delta, air, lines]|(8,[1,2,3],[1.0,1...|(8,[1,2,3],[1.387...|\n",
            "+-----+---------------+---------+--------+------+--------+-----+-----------+--------------------+-------------------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Term Frequency Vectorization  - Option 1 (Using hashingTF): \n",
        "#hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=20)\n",
        "#featurizedData = hashingTF.transform(clean_text)\n",
        "\n",
        "# Term Frequency Vectorization  - Option 2 (CountVectorizer)    : \n",
        "cv = CountVectorizer(inputCol=\"words\", outputCol=\"rawFeatures\", vocabSize = 1000)\n",
        "cvmodel = cv.fit(df)\n",
        "featurizedData = cvmodel.transform(df)\n",
        "\n",
        "vocab = cvmodel.vocabulary\n",
        "vocab_broadcast = sc.broadcast(vocab)\n",
        "\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idfModel = idf.fit(featurizedData)\n",
        "rescaledData = idfModel.transform(featurizedData)\n",
        "rescaledData.show(10)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}